{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[416],{1721:function(t,s,a){\"use strict\";a.r(s);var n=a(44),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[a(\"p\",[t._v(\"[TOC]\")]),t._v(\" \"),a(\"h1\",{attrs:{id:\"第五节-字符串命令-awk\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#第五节-字符串命令-awk\"}},[t._v(\"#\")]),t._v(\" 第五节 字符串命令：awk\")]),t._v(\" \"),a(\"p\",[t._v(\"一个强大的文本分析工具，把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行分析处理。\")]),t._v(\" \"),a(\"h2\",{attrs:{id:\"_1、基本用法\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1、基本用法\"}},[t._v(\"#\")]),t._v(\" 1、基本用法\")]),t._v(\" \"),a(\"p\",[t._v(\"awk [选项参数] ‘pattern1{action1} pattern2{action2}...’ filename\"),a(\"br\")]),t._v(\" \"),a(\"p\",[t._v(\"pattern：表示AWK在数据中查找的内容，就是匹配模式\"),a(\"br\")]),t._v(\" \"),a(\"p\",[t._v(\"action：在找到匹配内容时所执行的一系列命令\"),a(\"br\")]),t._v(\" \"),a(\"p\",[t._v(\"使用-F参数指定分隔符。\"),a(\"br\")]),t._v(\" \"),a(\"p\",[t._v(\"awk命令的内置变量包括：\")]),t._v(\" \"),a(\"table\",[a(\"thead\",[a(\"tr\",[a(\"th\",[t._v(\"变量名\")]),t._v(\" \"),a(\"th\",[t._v(\"说明\")])])]),t._v(\" \"),a(\"tbody\",[a(\"tr\",[a(\"td\",[t._v(\"FILENAME\")]),t._v(\" \"),a(\"td\",[t._v(\"文件名\")])]),t._v(\" \"),a(\"tr\",[a(\"td\",[t._v(\"NR\")]),t._v(\" \"),a(\"td\",[t._v(\"已读取的记录\")])]),t._v(\" \"),a(\"tr\",[a(\"td\",[t._v(\"NF\")]),t._v(\" \"),a(\"td\",[t._v(\"浏览记录的域的个数（切割后，列的个数）\")])])])]),t._v(\" \"),a(\"h2\",{attrs:{id:\"_2、测试\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2、测试\"}},[t._v(\"#\")]),t._v(\" 2、测试\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-shell extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 准备数据\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"root@hadoop101 datas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\"$ \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"sudo\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"cp\")]),t._v(\" /etc/passwd ./\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 搜索passwd文件以root关键字开头的所有行，并输出该行的第7列。\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"root@hadoop101 datas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\"$ \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"awk\")]),t._v(\" -F: \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'/^root/{print \"),a(\"span\",{pre:!0,attrs:{class:\"token variable\"}},[t._v(\"$7\")]),t._v(\"}'\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"passwd\")]),t._v(\" \\n/bin/bash\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 搜索passwd文件以root关键字开头的所有行，并输出该行的第1列和第7列，中间以“，”号分割。\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"root@hadoop101 datas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\"$ \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"awk\")]),t._v(\" -F: \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'/^root/{print \"),a(\"span\",{pre:!0,attrs:{class:\"token variable\"}},[t._v(\"$1\")]),t._v('\",\"'),a(\"span\",{pre:!0,attrs:{class:\"token variable\"}},[t._v(\"$7\")]),t._v(\"}'\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"passwd\")]),t._v(\" \\nroot,/bin/bash\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v('# 只显示/etc/passwd的第一列和第七列，以逗号分割，且在所有行前面添加列名user，shell在最后一行添加\"dahaige，/bin/zuishuai\"。')]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"root@hadoop101 datas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\"$ \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"awk\")]),t._v(\" -F \"),a(\"span\",{pre:!0,attrs:{class:\"token builtin class-name\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\\'BEGIN{print \"user, shell\"} {print '),a(\"span\",{pre:!0,attrs:{class:\"token variable\"}},[t._v(\"$1\")]),t._v('\",\"'),a(\"span\",{pre:!0,attrs:{class:\"token variable\"}},[t._v(\"$7\")]),t._v('} END{print \"dahaige,/bin/zuishuai\"}\\'')]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"passwd\")]),t._v(\"\\nuser, shell\\nroot,/bin/bash\\nbin,/sbin/nologin\\n。。。\\natguigu,/bin/bash\\ndahaige,/bin/zuishuai\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 将passwd文件中的用户id增加数值1并输出\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"root@hadoop101 datas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\"$ \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"awk\")]),t._v(\" -v \"),a(\"span\",{pre:!0,attrs:{class:\"token assign-left variable\"}},[t._v(\"i\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),t._v(\" -F: \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'{print \"),a(\"span\",{pre:!0,attrs:{class:\"token variable\"}},[t._v(\"$3\")]),t._v(\"+i}'\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"passwd\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"3\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"4\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 统计passwd文件名，每行的行号，每行的列数\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"root@hadoop101 datas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\"$ \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"awk\")]),t._v(\" -F: \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\\'{print \"filename:\"  FILENAME \", linenumber:\" NR  \",columns:\" NF}\\'')]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"passwd\")]),t._v(\" \\nfilename:passwd, linenumber:1,columns:7\\nfilename:passwd, linenumber:2,columns:7\\nfilename:passwd, linenumber:3,columns:7\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 切割IP\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"root@apple workspace\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# ifconfig | awk -F \\\" \\\" '/netmask/{print $2}'\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"192.168\")]),t._v(\".41.100\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"127.0\")]),t._v(\".0.1\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"192.168\")]),t._v(\".122.1\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# 查询sed.txt中空行所在的行号\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"root@hadoop101 datas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\"$ \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"awk\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'/^$/{print NR}'\")]),t._v(\" sed.txt \\n\"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5\")]),t._v(\"\\n\")])])]),a(\"p\",[t._v(\"PS：如果命令很长，可以使用反斜杠换行输入\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-shell extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-shell\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"root@apple workspace\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"# awk -F : \\\\\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\">\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'BEGIN{print \\\"user\"),a(\"span\",{pre:!0,attrs:{class:\"token entity\",title:\"\\\\t\"}},[t._v(\"\\\\t\")]),a(\"span\",{pre:!0,attrs:{class:\"token entity\",title:\"\\\\t\"}},[t._v(\"\\\\t\")]),t._v('shell\"} {print '),a(\"span\",{pre:!0,attrs:{class:\"token variable\"}},[t._v(\"$1\")]),t._v('\"'),a(\"span\",{pre:!0,attrs:{class:\"token entity\",title:\"\\\\t\"}},[t._v(\"\\\\t\")]),a(\"span\",{pre:!0,attrs:{class:\"token entity\",title:\"\\\\t\"}},[t._v(\"\\\\t\")]),t._v('\"'),a(\"span\",{pre:!0,attrs:{class:\"token variable\"}},[t._v(\"$7\")]),t._v('} END{print \"dahaige'),a(\"span\",{pre:!0,attrs:{class:\"token entity\",title:\"\\\\t\"}},[t._v(\"\\\\t\")]),a(\"span\",{pre:!0,attrs:{class:\"token entity\",title:\"\\\\t\"}},[t._v(\"\\\\t\")]),t._v(\"/bin/zuishuai\\\"}'\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"\\\\\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\">\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"passwd\")]),t._v(\"\\n\")])])]),a(\"p\",[a(\"RouterLink\",{attrs:{to:\"/pro006-Linux/lecture/chapter03/verse05-04-cut.html\"}},[t._v(\"上一条\")]),t._v(\" \"),a(\"RouterLink\",{attrs:{to:\"/pro006-Linux/lecture/chapter03/verse05-00-index.html\"}},[t._v(\"回目录\")]),t._v(\" \"),a(\"RouterLink\",{attrs:{to:\"/pro006-Linux/lecture/chapter03/verse05-06-sort.html\"}},[t._v(\"下一条\")])],1)])}),[],!1,null,null,null);s.default=e.exports}}]);","extractedComments":[]}